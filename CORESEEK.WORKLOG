[CMake化]
1 Mac 上编译，需要特别的 Patch
	+#ifdef __LITTLE_ENDIAN__
	+#	define USE_LITTLE_ENDIAN 1
	+#else
	+#	define USE_LITTLE_ENDIAN 0
	+#endif

2 直接使用 CMake 编译， 对应 sphinxversion.h 无法自动生成
3 直接使用 CMake， 对 XMLPipe2 数据源的支持缺失了

[Branding]
1 Change to 5.1

[Tokenizer]
1 切分 Cache
  { Cache 部分为可选，交给 Python 脚本处理 }
	Cache 需要综合考虑
	* 索引名
	* 字段名称
	* 文本正文
	* 分词法标号（rev）， 类似 last_modify_time
	在进行远程调用时，需要先查询 rev 号，

2 远过程调用
	
	使用 Python 扩展层，传入的为已经切分过的结果。

	使用 Magic 字符，
		当首字符为 0xFFFA 时， 
			表示后续的结果为已经切分过的；
		反之
			使用目前的切分方式。
		当首字母为 0xFFFA， 后续字符表示具体格式的 rev 号，从 0x41 ('A') 起跳
		Note:
			* 某些分词包返回的结果可能会吃掉某些字符，导致无法一一对应；
			* 可能会对原始文本进行大小写转换、简繁转换、同义词转换等
			* 可能会出现同义词扩展

		版本 0x41:
			后续保留 4bit，对应分词法词库变更的版本号，使用者需要与实际得到的版本号对比。如果不符，需要更新
			后续的数据，使用 `_? ` 切开， ? 可以是 x i s p 等;
			原来是 '/' 但是， Sphinx 默认的 / 会被吃掉，统一改为 _
			如果原文中有 _ 并且被切出，则为 __?; 如果在最后一位字符，则为 token__?
			x 原始文本
			i 进行过大小写归一化的原始文本
			e 根据其他规则扩展出的实体
			s 同义词扩展过的词
			p 对应词的读音
			其中，只有 x 会移动当前词的位置， 其他的均增加到之前的 token 所在的位置上

			？ 是否对这种扩展出得词进行特殊处理？ 比如增加 __s_ 前缀

3 Batch 处理 
	
	多份文档
		FieldDef
			FieldID	FieldName
		FieldDefEnd
		-----
		DocStart DocID
			FieldStart FieldID
				Ctx
			FieldEnd
		DocEnd
	可以直接处理为 JSON
	查询版本时，服务器端返回支持的格式 	
		JSON, CORESEEK/x41, CORESEEK/x42

4 URL 定义
	[prefix]/[算法名称]?version	查询当前的分词法版本，算法修改增加整数，词典修改增加小数（在万位）
	[prefix]/[算法名称]?json 		强制要求返回JSON格式的结果
	一次可以传入多个文档， 按字段分开
	DocStart {ctx}	DocStart {ctx}
	这里的 DocStart 需要被替换为一个 8字符的随机（不常见）字符串， 用于区分...
	在 Refer 里面，填写索引的名字，字段的名字

5 超时机制
	当服务器 错误时， 随机延长一段时间重试
	重试N次失败后，退出。
	如果是服务器不可达的错误，则等待、重试满10分钟后，再退出，
	等待的时间与重试的次数均可调节

6 查询时，可以直接使用 空格 作为切分方式。

[查询]
0 查询必须是预先切分好的词条，检索部分不在额外处理分词
1 从 Sphinx 的查询中， 需要把现有的查询转换为 AST-Tree
2 需要特别处理中文的切分，按照字段
3 需要进行同义词展开
4 需要修改字段的权重 & 词的权重
5 对于部分检索结果，可以进行缓存	
6 对于产品型号等实体信息， 通过扩展处理，对于分词部分，中英文联合的短语，需要断开。例如：
	GB2312 -> GB/x 2312/x GB2312/e
  这部分处理， 在分词部分。类似，对于时间的处理
  2012年10月 -> 2012/x 年/x  2012年/e 10/x 月/x 10月/e 2012年10月/e
7 对于查询，只支持使用 空格作为切分。

[数据源]
1 [done] 处理为推送的模式，Python Source II
2 保留原有版本的 Python Source
3 需要提供一个机制，记录全部入库的数据记录（用于确定那些数据 missing)


[分布式]


