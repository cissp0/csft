[CMake化]
1 Mac 上编译，需要特别的 Patch
	+#ifdef __LITTLE_ENDIAN__
	+#	define USE_LITTLE_ENDIAN 1
	+#else
	+#	define USE_LITTLE_ENDIAN 0
	+#endif

2 直接使用 CMake 编译， 对应 sphinxversion.h 无法自动生成
3 直接使用 CMake， 对 XMLPipe2 数据源的支持缺失了

[Branding]
1 Change to 5.1

[Tokenizer]
1 切分 Cache
	Cache 需要综合考虑
	* 字段名称
	* 文本正文
	* 分词法标号（rev）， 类似 last_modify_time
	在进行远程调用时，需要先查询 rev 号，

2 远过程调用
	
	使用 Python 扩展层，传入的为已经切分过的结果。

	使用 Magic 字符，
		当首字符为 0xFFFA 时， 
			表示后续的结果为已经切分过的；
		反之
			使用目前的切分方式。
		当首字母为 0xFFFA， 后续字符表示具体格式的 rev 号，从 0x41 ('A') 起跳
		Note:
			* 某些分词包返回的结果可能会吃掉某些字符，导致无法一一对应；
			* 可能会对原始文本进行大小写转换、简繁转换、同义词转换等
			* 可能会出现同义词扩展

		版本 0x41:
			后续保留 4bit，对应分词法词库变更的版本号，使用者需要与实际得到的版本号对比。如果不符，需要更新
			后续的数据，使用 `/? ` 切开， ? 可以是 x i s p 等
			x 原始文本
			i 进行过大小写归一化的原始文本
			e 根据其他规则扩展出的实体
			s 同义词扩展过的词
			p 对应词的读音
			其中，只有 x 会移动当前词的位置， 其他的均增加到之前的 token 所在的位置上

			？ 是否对这种扩展出得词进行特殊处理？ 比如增加 __s_ 前缀

3 Batch 处理 
	
	多份文档
		FieldDef
			FieldID	FieldName
		FieldDefEnd
		-----
		DocStart DocID
			FieldStart FieldID
				Ctx
			FieldEnd
		DocEnd
	可以直接处理为 JSON
	查询版本时，服务器端返回支持的格式 	
		JSON, CORESEEK/x41, CORESEEK/x42


[查询]
0 查询必须是预先切分好的词条，检索部分不在额外处理分词
1 从 Sphinx 的查询中， 需要把现有的查询转换为 AST-Tree
2 需要特别处理中文的切分，按照字段
3 需要进行同义词展开
4 需要修改字段的权重 & 词的权重
5 对于部分检索结果，可以进行缓存	
6 对于产品型号等实体信息， 通过扩展处理，对于分词部分，中英文联合的短语，需要断开。例如：
	GB2312 -> GB/x 2312/x GB2312/e
  这部分处理， 在分词部分。类似，对于时间的处理
  2012年10月 -> 2012/x 年/x  2012年/e 10/x 月/x 10月/e 2012年10月/e
7 对于查询，只支持使用 空格作为切分。

[数据源]
1 处理为推送的模式，Python Source II
2 保留原有版本的 Python Source




